---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


I am a postdoctoral research fellow in Snow Fellow A/Prof [Arnold Lining Ju](https://prerender.sydney.edu.au/https://www.sydney.edu.au/engineering/about/our-people/academic-staff/arnold-ju.html)'s group at the School of Biomedical Engineering, Faculty of Engineering, The University of Sydney.
I obtained my PhD degree from the School of Computer Science, USYD, supervised by Prof [Dacheng Tao](https://scholar.google.com/citations?user=RwlJNLcAAAAJ) and Dr [Jing Zhang](https://scholar.google.com.hk/citations?user=9jH5v74AAAAJ), 2021-2024. I obtained my Master's degree from Tsinghua University, supervised by A/Prof [Bo Yuan](http://www.global-optimization.com/boyuan/) and worked closely with Prof [Xiu Li](https://scholar.google.com/citations?user=Xrh1OIUAAAAJ&hl=en), 2017-2020.

My research interests lie in artificial intelligence, computer vision, autonomous driving, AI for biomedical science and engineering, and digital healthcare.

I am passionate about advancing multidisciplinary research powered by AI and am always open to collaboration, lecturing, and building meaningful connections. Please feel free to reach out!


<!-- I obtained a PhD degree from Peking University supervised by A/Prof [Tingting Jiang](http://www.vie.group/ttj) and Prof [Yizhou Wang](https://cfcs.pku.edu.cn/english/people/faculty/yizhouwang/index.htm), and a Bachelor of Engineering from Tongji University. 
 -->


<!-- My research interests lie in intelligent surgical skill assessment using computer vision and generative artificial intelligence.
 -->

<!-- My research seeks to answer two principal questions, i.e., ‚Äúwhat‚Äù is performed and ‚Äúhow well‚Äù it is performed, by observing human activities from visual or multi-modal data and using generative learning frameworks. This is pivotal to human-centric machine intelligence to comprehend, collaborate with, and amplify human capabilities in daily and professional lives.  -->

<!-- This stems from the notion that human behavior is inherently a generative act, conditioned on driving goals, environmental contexts, and prior experiences. Such an ‚Äúunderstanding-by-generating" paradigm enables unsupervised learning of human activities. I also feel excited about delving into human skill assessment by viewing skills as emergent attributes generated from repeated action operations. My goal is to understand skill acquisition through generative learning, by connecting the generative process of actions and the learning curve of skills from novice to expert.  -->

<!-- My research about generative surgical AI lies in intelligent analysis of surgeries to enhance patient care and surgical education. The short-term goal is to demystify the intricacies of surgical procedures, e.g., tool usage and event patterns, using videos from minimally invasive or robotic surgeries, and establish links with surgical skills and clinical outcomes. My previous works have shown promising results; AI-based skill assessment on in-vivo clinical gastrectomy surgeries demonstrated remarkable correlations with the expert consensus. The long-term vision is to bring intelligence into the multimodal data of surgeries in an enriched context beyond videos, including perioperative imaging, robotic kinematics, textual records, and environmental and physiological metrics, to offer holistic insights into surgical procedures. By utilizing specialized models, foundational models, and specialized-foundational models of machine learning, my research aims to advance surgical data science from concept to translation in the next generation of surgery.
 -->
<!-- My research is rooted in understanding human action and skills with computer vision and generative artificial intelligence, which also involves fundamental problems in generative diffusion models and applications in automatic surgical skill assessment.
 -->
<!-- My research interests lie in computer vision, artificial intelligence, and related topics in the medical domain, specifically including:
- Generative AI, Diffusion Models
- Surgical AI, Surgical Skill Assessment
- Video Understanding and Action Analysis -->

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).
 -->


<span class='anchor' id='news'></span>

# üî• News
- *2025.03*: One paper got accepted by Advanced Materials 2025 (IF: 26.8)! Congratulations to Charles!
- *2025.06*: üéâ Excited to share that our project **"SmartClot-AI: Next-Generation Intelligent Point-of-Care Coagulation Testing and Decision Support System"** has been awarded the **2025‚Äì2026 DVCR Proof-of-Concept (POC) Fund ‚Äì STEM stream** by The University of Sydney, with funding support of **A$80,000**! Even more exciting ‚Äî this is my first funding as Chief Investigator (**CIA**)! üéâüéâ
- *2025.03*: One paper accepted by ICME 2025.
- *2025.03*: One paper accepted by ACS Sensors.
- *2024.12*: One paper accepted by Applied Intelligence.
- *2024.09*: One paper accepted by NeurIPs 2024.
- *2024.07*: One paper accepted by ECCV 2024.
- *2024.02*: One paper accepted by CVPR 2024. 
<!-- *2024.02*: I will serve as an Area Chair for MICCAI 2024.  -->

<span class='anchor' id='publications'></span>





<br>

# üìù Robust and Efficient AI for Autonomous Driving Sensing and Perception, Computer Vision


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/CVPR24_mainfigure.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_UniMix_Towards_Domain_Adaptive_and_Generalizable_LiDAR_Semantic_Segmentation_in_CVPR_2024_paper.html) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>

**Haimei Zhao**, Jing Zhang, Zhuo Chen, Shanshan Zhao, Dacheng Tao

*IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024*



</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2024</div><img src='images/mainfigure_AAAI.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Simdistill: Simulated multi-modal distillation for bev 3d object detection](https://ojs.aaai.org/index.php/AAAI/article/view/28577) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:qjMakFHDy7sC'></span></strong>

**Haimei Zhao**, Qiming Zhang, Shanshan Zhao, Zhe Chen, Jing Zhang, Dacheng Tao

*Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2024*

<!-- [[Code]](https://github.com/Finspire13/CMCS-Temporal-Action-Localization) [[Poster]](http://www.vie.group/media/pdf/CVPRÊµ∑Êä•_ldc_final.pdf)
-->

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MIR 2024</div><img src='images/frameF.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[On Robust Cross-View Consistency in Self-Supervised Monocular Depth Estimation](https://link.springer.com/article/10.1007/s11633-023-1474-0) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:_FxGoFyzp5QC'></span></strong>

**Haimei Zhao**, Jing Zhang, Zhuo Chen, Bo Yuan, Dacheng Tao

*Machine Intelligence Research, 2024*



</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2022</div><img src='images/network2_ECCV.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Jperceiver: Joint perception network for depth, pose and layout estimation in driving scenes](https://link.springer.com/chapter/10.1007/978-3-031-19839-7_41) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:_FxGoFyzp5QC'></span></strong>

**Haimei Zhao**, Jing Zhang, Sen Zhang, Dacheng Tao

*European Conference on Computer Vision (ECCV), 2022*



</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/figure2_ECCV2024.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[MapDistill: Boosting Efficient HD Map Construction via Camera-LiDAR Fusion Model Distillation](https://arxiv.org/abs/2407.11682) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:_FxGoFyzp5QC'></span></strong>

Xiaoshuai Hao, Ruikai Li, ... , **Haimei Zhao**#, Jing Zhang#

*European Conference on Computer Vision (ECCV), 2024*



</div>
</div>
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/framework_NIPS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Is Your HD Map Constructor Reliable under Sensor Corruptions?](https://arxiv.org/abs/2406.12214) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:_FxGoFyzp5QC'></span></strong>

Xiaoshuai Hao, Mengchuan Wei, Yifan Yang, **Haimei Zhao**, ... , Lingdong Kong, Jing Zhang

*Conference on Neural Information Processing Systems (NeurIPS), 2024*



</div>
</div>






- [STViT: Improving Self-Supervised Multi-Camera Depth Estimation with Spatial-Temporal Context and Adversarial Geometry Regularization](https://ojs.aaai.org/index.php/AAAI/article/view/30429)<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:LkGwnXOMwfcC'></span></strong>, Zhuo Chen*, **Haimei Zhao***, Bo Yuan, Xiu Li. Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2024

- [Deep corner](https://link.springer.com/article/10.1007/s11263-023-01837-3)<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:ufrVoPGSRksC'></span></strong>, Shanshan Zhao, Mingming Gong,**Haimei Zhao**, Jing Zhang, Dacheng Tao. *International Journal of Computer Vision (IJCV), 2023*

- [SPH-Net: Hyperspectral Image Super-Resolution via Smoothed Particle Hydrodynamics Modeling](https://ieeexplore.ieee.org/abstract/document/10302422)<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:roLk4NBRz8UC'></span></strong>, Mingjin Zhang, Jiamin Xu, Jing Zhang, **Haimei Zhao**, Wenteng Shang, Xinbo Gao. *IEEE Transactions on Cybernetics (TCYB), 2023*

- [Collaborative learning of depth estimation, visual odometry and camera relocalization from monocular videos](https://dl.acm.org/doi/abs/10.5555/3491440.3491508)<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:roLk4NBRz8UC'></span></strong>, **Haimei Zhao**, Wei Bian, Bo Yuan, Dacheng Tao. *International Conference on International Joint Conferences on Artificial Intelligence (IJCAI), 2020*





<br>


# üìù AI for Biomedical Science and Engineering, Digital Health 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Med-X 2024</div><img src='images/MedX.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Strategic reuse of rapid antigen tests for coagulation status assessment: an integrated machine learning approach](https://link.springer.com/article/10.1007/s44258-024-00025-3)
<!-- <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:_kc_bZDykSQC'></span></strong>
 -->

Allan Sun, Arian Nasser, Chaohao Chen, Yunduo Charles Zhao, **Haimei Zhao**, ... , Lining Arnold Ju

*Med-X, 2024*

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACS Sensors 2025</div><img src='images/acs-sensors.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Sensing the Future of Thrombosis Management: Integrating Vessel-on-a-Chip Models, Advanced Biosensors, and AI-Driven Digital Twins]([https://link.springer.com/article/10.1007/s44258-024-00025-3](https://pubs.acs.org/doi/full/10.1021/acssensors.4c02764))
<!-- <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:_kc_bZDykSQC'></span></strong>
 -->

Yunduo Charles Zhao, Zihao Wang, **Haimei Zhao**, ... , Lining Arnold Ju

*ACS Sensors, 2025*

</div>
</div>

<br>



# üìù Generative AI


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2024</div><img src='images/framework-first-3dgan.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Dual Mapping of 2D StyleGAN for 3D-Aware Image Generation and Manipulation](https://ojs.aaai.org/index.php/AAAI/article/view/30428) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:Y0pCki6q_DkC'></span></strong>

Zhuo Chen, **Haimei Zhao**, Chaoyue Wang, Bo Yuan, Xiu Li

*Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2024*


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2022</div><img src='images/fig1_MM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[D^2Animator: Dual Distillation of StyleGAN For High-Resolution Face Animation](https://dl.acm.org/doi/pdf/10.1145/3503161.3548002) <strong><span class='show_paper_citations' data='ElujT6oAAAAJ:YsMSGLbcyi4C'></span></strong>

Zhuo Chen, Chaoyue Wang, **Haimei Zhao**, Bo Yuan, Xiu Li

*Proceedings of the 30th ACM International Conference on Multimedia (ACM MM), 2022*



</div>
</div>





# üåü Competition


- [The robodrive challenge: Drive anytime anywhere in any condition](https://arxiv.org/abs/2405.08816)<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:Se3iqnhoufwC'></span></strong>, The Third Place. *IEEE Conference on Robotics and Automation (ICRA 2024)*.

# üåü Patent
- Method and system for determining and indication of blood coagulability, Allan Sun, Arnold Lining Ju, Arian Nasser, **Haimei Zhao**. *Australia Filed Patent Appl. No: 2024902177, TRL: 5*

- Ultrafast Automatic Fabrication Process for Versatile 3D Microchannel Fabrications. Arnold Lining Ju, Charles Yunduo Zhao, Zihao Wang, **Haimei Zhao**, Nicole Alex Yap.





<!-- <span class='anchor' id='awards'></span>

# üéñ Awards
- *2024*, ICDM Best Student Paper Award, 1 out of 885
- *2021*, Peking University Tianchuang Scholarship, Top 5% PhDs
- *2020*, Microsoft Research Asia Fellowship Nomination, Top 25 PhDs in Asia-Pacific
- *2019*, Peking University Principle's Scholarship, Top 5% PhDs
- *2019*, Peking University Academic Innovation Award, Top 3% PhDs
- *2017*, Shanghai Outstanding Bachelor Graduate, Top 2% Graduates -->


# üåü Awards and Grants

- *2025 - 2026*, The University of Sydney DVCR Proof-of-Concept (POC) Fund ‚Äì STEM stream (CIA). ‚ÄúSmartClot-AI: Next-Generation Intelligent Point-of-Care Coagulation Testing and Decision Support System‚Äù, A$80,000.

- *2024 - 2025*, The University of Sydney ‚Äì PERIscope Commercialisation Award (AI Lead), $61,500.

- *2024*, The University of Sydney Nano Institute ‚Äì NanoPitch Health People‚Äôs Choice Award (AI Lead), $5,000.

- *2024*, Faculty of Engineering Career Advancement Award, The University of Sydney, $20,000.

- *2021 - 2024*, Faculty of Engineering Research Scholarship, The University of Sydney, $3,7000 Per Year

- *2018*, National Scholarship, Tsinghua University, $6,000, Top 1 Postgraduate.

- *2016*, Science and Technology Contribution Award, Changchun University of Science and Technology Scholarship Fund, $1,000, Top 1 Undergraduate.


<!-- - *2024 - 2025*, Lead CI, $15000 AUD, Digital Sciences Initiative Ignite Award, USYD

- *2023 - 2024*, Lead CI, $7840 USD, Google Cloud Research Credits Award 

- *2024 Q1-Q2*, Lead CI, 40000 GPU Hours (40K AUD Equivalent), The National Computational Infrastructure (NCI) AI Flagship Scheme

- *2024 Q1-Q2*, Lead CI, 12000 GPU Hours (12K AUD Equivalent), Sydney Informatics Hub (SIH) HPC Allocation Scheme 2024 Round 1

- *2023 Q1-Q2*, Lead CI, 10000 GPU Hours (10K AUD Equivalent), The National Computational Infrastructure (NCI) Adapter Scheme 
 

- *2024 - 2025*, Digital Sciences Initiative Ignite Award, USYD

- *2023 - 2024*, Google Cloud Research Credits Award 

- *2024 Q1-Q2*, The National Computational Infrastructure (NCI) AI Flagship Scheme

- *2024 Q1-Q2*, Sydney Informatics Hub (SIH) HPC Allocation Scheme 2024 Round 1

- *2023 Q1-Q2*, The National Computational Infrastructure (NCI) Adapter Scheme 
-->

<span class='anchor' id='services'></span>

# ‚ô•Ô∏è Services and Engagement

- *2025-*, ICT Director of School of Biomedical Engineering, USYD
- *2024*, Diversity, Equity, and Inclusion (DEI) Committee, Ju Lab, School of Biomedical Engineering, USYD
- *2022-2023*, Higher Degree Research (HDR) Student Committee, School of Computer Science, USYD
- Program Committee Member of CVPR, ECCV, ACM MM, ECAI, ICPR
- Invited Reviewer of TIP, TMM, KBS, IEEE Signal Processing Letters

# -

**Contact:** h.zhao at sydney.edu.au

**Last Update:** Oct 28, 2024

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=EPHsmQIJLbnhIay_lL2JI0tJ1EPMrLTnAPwg8zuvHkY&cl=ffffff&w=300"></script>
